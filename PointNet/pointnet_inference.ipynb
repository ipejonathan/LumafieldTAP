{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4dc99b0",
   "metadata": {},
   "source": [
    "# PointNet Semantic Segmentation Inference\n",
    "\n",
    "Model and code modified from https://www.kaggle.com/code/mahdiasdzd/pointnet/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0168761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import pandas as pd\n",
    "# import glob\n",
    "# import random\n",
    "# from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# DeepLearning \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "# import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32647d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.6\n",
      "2.9.0+cu130\n",
      "Thu Nov  6 11:09:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 581.15                 Driver Version: 581.15         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 2080 ...  WDDM  |   00000000:2D:00.0  On |                  N/A |\n",
      "| 12%   55C    P0             41W /  250W |    5379MiB /   8192MiB |      7%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            7668    C+G   ...\\envs\\lumafieldtap\\python.exe      N/A      |\n",
      "|    0   N/A  N/A            8604    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A            9016    C+G   ...4__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A           10636    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           12312    C+G   ...em_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A           13124    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           13292    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           14232    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           15100    C+G   ...ows\\System32\\NahimicSvc64.exe      N/A      |\n",
      "|    0   N/A  N/A           15620    C+G   ...lpaper_engine\\wallpaper32.exe      N/A      |\n",
      "|    0   N/A  N/A           17704    C+G   ...bwe\\Microsoft.Msn.Weather.exe      N/A      |\n",
      "|    0   N/A  N/A           18304    C+G   ...4__w2gh52qy24etm\\Nahimic3.exe      N/A      |\n",
      "|    0   N/A  N/A           18528    C+G   ...ORSAIR iCUE Software\\iCUE.exe      N/A      |\n",
      "|    0   N/A  N/A           19232    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           19844    C+G   ...Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A           21840    C+G   ...ftware\\CorsairOsdLauncher.exe      N/A      |\n",
      "|    0   N/A  N/A           23604    C+G   ...ekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A           25816    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           32840    C+G   ...6)\\Dropbox\\Client\\Dropbox.exe      N/A      |\n",
      "|    0   N/A  N/A           38228    C+G   ...a\\Roaming\\Spotify\\Spotify.exe      N/A      |\n",
      "|    0   N/A  N/A           42748    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           46436    C+G   ...cord\\app-1.0.9213\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           47476    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           47908    C+G   ...cord\\app-1.0.9213\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A           48700    C+G   ...h_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A           50576    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(np.__version__)\n",
    "print(torch.__version__)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ac1736",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc7e4739",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STN3d(nn.Module):\n",
    "\n",
    "    def __init__(self, num_points = 2500):\n",
    "        super(STN3d, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        \n",
    "        self.mp1 = torch.nn.MaxPool1d(num_points)\n",
    "        \n",
    "        # FC layers\n",
    "        self.fc1 = nn.Linear(1024, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 9)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.bn4 = nn.BatchNorm1d(512)\n",
    "        self.bn5 = nn.BatchNorm1d(256)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        \n",
    "        # Expected input shape = (bs, 3, num_points)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.mp1(x)\n",
    "        x = x.view(-1, 1024)\n",
    "\n",
    "        x = F.relu(self.bn4(self.fc1(x)))\n",
    "        x = F.relu(self.bn5(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        iden = Variable(torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32))).view(1,9).repeat(batchsize,1)\n",
    "        if x.is_cuda:\n",
    "            iden = iden.cuda()\n",
    "        x = x + iden\n",
    "        x = x.view(-1, 3, 3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c474867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenShape(nn.Module):\n",
    "    def __init__(self, num_points = 2500):\n",
    "        super(OpenShape, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.mp1 = torch.nn.MaxPool1d(num_points)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = self.mp1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c22d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetfeat(nn.Module):\n",
    "\n",
    "    def __init__(self, num_points = 2500, global_feat = True):\n",
    "        super(PointNetfeat, self).__init__()\n",
    "        self.stn = STN3d(num_points = num_points)\n",
    "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
    "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
    "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(1024)\n",
    "        self.mp1 = torch.nn.MaxPool1d(num_points)\n",
    "        self.num_points = num_points\n",
    "        self.global_feat = global_feat\n",
    "        self.OpenShape = OpenShape(num_points = num_points)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        trans = self.stn(x)\n",
    "        x = x.transpose(2,1)\n",
    "        x = torch.bmm(x, trans)\n",
    "        x = x.transpose(2,1)\n",
    "        x = F.elu(self.bn1(self.conv1(x)))\n",
    "        pointfeat = x\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        x = self.mp1(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        if self.global_feat:\n",
    "            return x, trans\n",
    "        else:\n",
    "            x = x.view(-1, 1024, 1).repeat(1, 1, self.num_points)\n",
    "            return torch.cat([x, pointfeat], 1), trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b90b1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointNetDenseSeg(nn.Module):\n",
    "    def __init__(self, num_points=2500, num_classes=16, num_instances=10):\n",
    "        super(PointNetDenseSeg, self).__init__()\n",
    "        self.num_points = num_points\n",
    "        self.num_classes = num_classes\n",
    "        self.num_instances = num_instances\n",
    "\n",
    "        # Feature extraction using PointNetfeat\n",
    "        self.feat = PointNetfeat(num_points, global_feat=False)\n",
    "\n",
    "        # Semantic segmentation layers\n",
    "        self.conv1_sem = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2_sem = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3_sem = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4_sem = torch.nn.Conv1d(128, num_classes, 1)\n",
    "        self.bn1_sem = nn.BatchNorm1d(512)\n",
    "        self.bn2_sem = nn.BatchNorm1d(256)\n",
    "        self.bn3_sem = nn.BatchNorm1d(128)\n",
    "\n",
    "        # Instance segmentation layers\n",
    "        self.conv1_inst = torch.nn.Conv1d(1088, 512, 1)\n",
    "        self.conv2_inst = torch.nn.Conv1d(512, 256, 1)\n",
    "        self.conv3_inst = torch.nn.Conv1d(256, 128, 1)\n",
    "        self.conv4_inst = torch.nn.Conv1d(128, num_instances, 1)\n",
    "        self.bn1_inst = nn.BatchNorm1d(512)\n",
    "        self.bn2_inst = nn.BatchNorm1d(256)\n",
    "        self.bn3_inst = nn.BatchNorm1d(128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.size()[0]\n",
    "        x, trans = self.feat(x)\n",
    "\n",
    "        # Semantic segmentation branch\n",
    "        x_sem = F.relu(self.bn1_sem(self.conv1_sem(x)))\n",
    "        x_sem = F.relu(self.bn2_sem(self.conv2_sem(x_sem)))\n",
    "        x_sem = F.relu(self.bn3_sem(self.conv3_sem(x_sem)))\n",
    "        x_sem = self.conv4_sem(x_sem)\n",
    "\n",
    "        # Instance segmentation branch\n",
    "        x_inst = F.relu(self.bn1_inst(self.conv1_inst(x)))\n",
    "        x_inst = F.relu(self.bn2_inst(self.conv2_inst(x_inst)))\n",
    "        x_inst = F.relu(self.bn3_inst(self.conv3_inst(x_inst)))\n",
    "        x_inst = self.conv4_inst(x_inst)\n",
    "\n",
    "        return x_sem, x_inst, trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d2c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointNetDenseSeg(\n",
       "  (feat): PointNetfeat(\n",
       "    (stn): STN3d(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (mp1): MaxPool1d(kernel_size=100000, stride=100000, padding=0, dilation=1, ceil_mode=False)\n",
       "      (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (fc3): Linear(in_features=256, out_features=9, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "    (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "    (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (mp1): MaxPool1d(kernel_size=100000, stride=100000, padding=0, dilation=1, ceil_mode=False)\n",
       "    (OpenShape): OpenShape(\n",
       "      (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,))\n",
       "      (conv2): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      (conv3): Conv1d(128, 1024, kernel_size=(1,), stride=(1,))\n",
       "      (mp1): MaxPool1d(kernel_size=100000, stride=100000, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (conv1_sem): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
       "  (conv2_sem): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (conv3_sem): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "  (conv4_sem): Conv1d(128, 16, kernel_size=(1,), stride=(1,))\n",
       "  (bn1_sem): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2_sem): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3_sem): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_inst): Conv1d(1088, 512, kernel_size=(1,), stride=(1,))\n",
       "  (conv2_inst): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "  (conv3_inst): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "  (conv4_inst): Conv1d(128, 10, kernel_size=(1,), stride=(1,))\n",
       "  (bn1_inst): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2_inst): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3_inst): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_points = 100000\n",
    "classifier = PointNetDenseSeg(num_points = num_points)\n",
    "classifier.load_state_dict(torch.load('pointnet_se_seg.pth'))\n",
    "classifier = classifier.to(device)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99375c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: feat.stn.conv1.weight, Weights/Biases: \n",
      " tensor([[[-0.2062],\n",
      "         [ 0.0188],\n",
      "         [-0.2074]],\n",
      "\n",
      "        [[ 0.3418],\n",
      "         [-0.2682],\n",
      "         [ 0.3939]],\n",
      "\n",
      "        [[-0.1998],\n",
      "         [-0.3774],\n",
      "         [-0.2125]],\n",
      "\n",
      "        [[ 0.4823],\n",
      "         [ 0.0336],\n",
      "         [-0.4573]],\n",
      "\n",
      "        [[-0.4988],\n",
      "         [ 0.1188],\n",
      "         [ 0.5872]],\n",
      "\n",
      "        [[-0.3966],\n",
      "         [-0.0720],\n",
      "         [-0.1775]],\n",
      "\n",
      "        [[ 0.5281],\n",
      "         [ 0.1959],\n",
      "         [ 0.0195]],\n",
      "\n",
      "        [[ 0.0723],\n",
      "         [-0.1757],\n",
      "         [-0.5828]],\n",
      "\n",
      "        [[ 0.1966],\n",
      "         [-0.2205],\n",
      "         [-0.2059]],\n",
      "\n",
      "        [[ 0.4263],\n",
      "         [ 0.2155],\n",
      "         [-0.2420]],\n",
      "\n",
      "        [[ 0.0096],\n",
      "         [-0.1004],\n",
      "         [-0.3947]],\n",
      "\n",
      "        [[-0.3425],\n",
      "         [ 0.1092],\n",
      "         [ 0.2810]],\n",
      "\n",
      "        [[ 0.2617],\n",
      "         [ 0.3500],\n",
      "         [-0.2710]],\n",
      "\n",
      "        [[ 0.5850],\n",
      "         [-0.2367],\n",
      "         [ 0.6039]],\n",
      "\n",
      "        [[ 0.4725],\n",
      "         [ 0.5132],\n",
      "         [-0.1394]],\n",
      "\n",
      "        [[ 0.5483],\n",
      "         [ 0.3627],\n",
      "         [ 0.3454]],\n",
      "\n",
      "        [[ 0.0697],\n",
      "         [-0.1757],\n",
      "         [ 0.5767]],\n",
      "\n",
      "        [[ 0.1931],\n",
      "         [-0.3580],\n",
      "         [ 0.1905]],\n",
      "\n",
      "        [[-0.4981],\n",
      "         [ 0.2689],\n",
      "         [ 0.3266]],\n",
      "\n",
      "        [[ 0.1884],\n",
      "         [-0.1866],\n",
      "         [-0.2385]],\n",
      "\n",
      "        [[-0.2008],\n",
      "         [-0.5768],\n",
      "         [-0.0645]],\n",
      "\n",
      "        [[-0.2773],\n",
      "         [ 0.5444],\n",
      "         [-0.3940]],\n",
      "\n",
      "        [[-0.5449],\n",
      "         [ 0.5233],\n",
      "         [-0.0638]],\n",
      "\n",
      "        [[-0.4738],\n",
      "         [ 0.3604],\n",
      "         [ 0.2086]],\n",
      "\n",
      "        [[ 0.5880],\n",
      "         [-0.4573],\n",
      "         [ 0.3257]],\n",
      "\n",
      "        [[-0.2344],\n",
      "         [ 0.3748],\n",
      "         [-0.2530]],\n",
      "\n",
      "        [[-0.4745],\n",
      "         [ 0.4836],\n",
      "         [ 0.0045]],\n",
      "\n",
      "        [[-0.0292],\n",
      "         [ 0.0706],\n",
      "         [-0.5571]],\n",
      "\n",
      "        [[ 0.0716],\n",
      "         [ 0.5147],\n",
      "         [ 0.4227]],\n",
      "\n",
      "        [[-0.4323],\n",
      "         [-0.3270],\n",
      "         [-0.2596]],\n",
      "\n",
      "        [[ 0.1220],\n",
      "         [-0.1890],\n",
      "         [-0.2295]],\n",
      "\n",
      "        [[-0.4378],\n",
      "         [ 0.0909],\n",
      "         [ 0.2632]],\n",
      "\n",
      "        [[ 0.4333],\n",
      "         [-0.3723],\n",
      "         [ 0.1259]],\n",
      "\n",
      "        [[ 0.2499],\n",
      "         [ 0.2522],\n",
      "         [ 0.2030]],\n",
      "\n",
      "        [[-0.0729],\n",
      "         [-0.5541],\n",
      "         [-0.2852]],\n",
      "\n",
      "        [[-0.0239],\n",
      "         [-0.4937],\n",
      "         [ 0.5004]],\n",
      "\n",
      "        [[-0.2198],\n",
      "         [-0.0061],\n",
      "         [-0.2263]],\n",
      "\n",
      "        [[-0.3881],\n",
      "         [-0.1139],\n",
      "         [ 0.1140]],\n",
      "\n",
      "        [[ 0.5015],\n",
      "         [-0.0331],\n",
      "         [ 0.0843]],\n",
      "\n",
      "        [[-0.0936],\n",
      "         [ 0.4685],\n",
      "         [-0.0167]],\n",
      "\n",
      "        [[-0.0852],\n",
      "         [-0.1632],\n",
      "         [ 0.4715]],\n",
      "\n",
      "        [[-0.2161],\n",
      "         [ 0.4894],\n",
      "         [ 0.2501]],\n",
      "\n",
      "        [[-0.4522],\n",
      "         [-0.4304],\n",
      "         [ 0.3598]],\n",
      "\n",
      "        [[-0.4811],\n",
      "         [ 0.2077],\n",
      "         [ 0.5378]],\n",
      "\n",
      "        [[-0.5034],\n",
      "         [-0.4882],\n",
      "         [-0.2663]],\n",
      "\n",
      "        [[ 0.0290],\n",
      "         [ 0.3674],\n",
      "         [-0.2906]],\n",
      "\n",
      "        [[-0.1884],\n",
      "         [ 0.5162],\n",
      "         [ 0.2103]],\n",
      "\n",
      "        [[ 0.1015],\n",
      "         [ 0.1091],\n",
      "         [ 0.2667]],\n",
      "\n",
      "        [[ 0.2308],\n",
      "         [-0.5231],\n",
      "         [ 0.1588]],\n",
      "\n",
      "        [[ 0.5002],\n",
      "         [ 0.2338],\n",
      "         [ 0.0809]],\n",
      "\n",
      "        [[ 0.0501],\n",
      "         [-0.0825],\n",
      "         [-0.4042]],\n",
      "\n",
      "        [[ 0.3467],\n",
      "         [ 0.0175],\n",
      "         [-0.4698]],\n",
      "\n",
      "        [[ 0.3933],\n",
      "         [-0.3722],\n",
      "         [-0.4552]],\n",
      "\n",
      "        [[ 0.3762],\n",
      "         [ 0.1802],\n",
      "         [ 0.0659]],\n",
      "\n",
      "        [[-0.5317],\n",
      "         [ 0.0537],\n",
      "         [ 0.1823]],\n",
      "\n",
      "        [[ 0.2133],\n",
      "         [-0.4792],\n",
      "         [-0.4975]],\n",
      "\n",
      "        [[ 0.0395],\n",
      "         [-0.1864],\n",
      "         [-0.3145]],\n",
      "\n",
      "        [[-0.1038],\n",
      "         [-0.4454],\n",
      "         [-0.3629]],\n",
      "\n",
      "        [[ 0.3263],\n",
      "         [-0.0157],\n",
      "         [-0.0786]],\n",
      "\n",
      "        [[-0.3565],\n",
      "         [-0.3647],\n",
      "         [-0.1882]],\n",
      "\n",
      "        [[ 0.3525],\n",
      "         [-0.0367],\n",
      "         [ 0.2935]],\n",
      "\n",
      "        [[ 0.3670],\n",
      "         [ 0.2864],\n",
      "         [-0.4180]],\n",
      "\n",
      "        [[ 0.5429],\n",
      "         [ 0.4774],\n",
      "         [-0.4748]],\n",
      "\n",
      "        [[ 0.4463],\n",
      "         [-0.2972],\n",
      "         [ 0.0417]]], device='cuda:0')\n",
      "torch.Size([64, 3, 1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in classifier.named_parameters():\n",
    "    print(f\"Layer: {name}, Weights/Biases: \\n {param.data}\")\n",
    "    print(param.data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde5cbd6",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38db9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ShapeNetDataset(torch.utils.data.Dataset):\n",
    "#     def __init__(self, root_dir, split_type, num_samples=2500):\n",
    "#         self.root_dir = root_dir\n",
    "#         self.split_type = split_type\n",
    "#         self.num_samples = num_samples\n",
    "#         with open(os.path.join(root_dir, f'{self.split_type}_split.json'), 'r') as f:\n",
    "#             self.split_data = json.load(f)       \n",
    "            \n",
    "#     def __getitem__(self, index):\n",
    "#         # read point cloud data\n",
    "#         class_id, class_name, point_cloud_path, seg_label_path = self.split_data[index]\n",
    "        \n",
    "#         # point cloud data\n",
    "#         point_cloud_path = os.path.join(self.root_dir, point_cloud_path)\n",
    "#         pc_data = np.load(point_cloud_path)\n",
    "        \n",
    "#         # segmentation labels\n",
    "#         # -1 is to change part values from [1-16] to [0-15]\n",
    "#         # which helps when running segmentation\n",
    "#         pc_seg_labels = np.loadtxt(os.path.join(self.root_dir, seg_label_path)).astype(np.int8) - 1\n",
    "#         #pc_seg_labels = pc_seg_labels.reshape(pc_seg_labels.size,1)\n",
    "        \n",
    "#         # Sample fixed number of points\n",
    "#         num_points = pc_data.shape[0]\n",
    "#         if num_points < self.num_samples:\n",
    "#             # Duplicate random points if the number of points is less than max_num_points\n",
    "#             additional_indices = np.random.choice(num_points, self.num_samples - num_points, replace=True)\n",
    "#             pc_data = np.concatenate((pc_data, pc_data[additional_indices]), axis=0)\n",
    "#             pc_seg_labels = np.concatenate((pc_seg_labels, pc_seg_labels[additional_indices]), axis=0)\n",
    "                \n",
    "#         else:\n",
    "#             # Randomly sample max_num_points from the available points\n",
    "#             random_indices = np.random.choice(num_points, self.num_samples)\n",
    "#             pc_data = pc_data[random_indices]\n",
    "#             pc_seg_labels = pc_seg_labels[random_indices]\n",
    "        \n",
    "#         # return variable\n",
    "#         data_dict= {}\n",
    "#         data_dict['class_id'] = class_id\n",
    "#         data_dict['class_name'] = class_name        \n",
    "#         data_dict['points'] = pc_data \n",
    "#         data_dict['seg_labels'] = pc_seg_labels \n",
    "#         return data_dict        \n",
    "                    \n",
    "#     def __len__(self):\n",
    "#         return len(self.split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0ed646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch_list):\n",
    "#     ret = {}\n",
    "#     ret['class_id'] =  torch.from_numpy(np.array([x['class_id'] for x in batch_list])).long()\n",
    "#     ret['class_name'] = np.array([x['class_name'] for x in batch_list])\n",
    "#     ret['points'] = torch.from_numpy(np.stack([x['points'] for x in batch_list], axis=0)).float()\n",
    "#     ret['seg_labels'] = torch.from_numpy(np.stack([x['seg_labels'] for x in batch_list], axis=0)).long()\n",
    "#     return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cf8b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import open3d as o3d\n",
    "\n",
    "# class SinglePLYDataset(Dataset):\n",
    "#     def __init__(self, ply_path, n_points=2048, with_normals=False):\n",
    "#         self.ply_path = ply_path\n",
    "#         self.n_points = n_points\n",
    "#         self.with_normals = with_normals\n",
    "#         self._prepare()\n",
    "\n",
    "#     def _prepare(self):\n",
    "#         pcd = o3d.io.read_point_cloud(self.ply_path)\n",
    "#         pts = np.asarray(pcd.points, dtype=np.float32)\n",
    "#         if self.with_normals:\n",
    "#             if not pcd.has_normals():\n",
    "#                 pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "#             feats = np.asarray(pcd.normals, dtype=np.float32)\n",
    "#         else:\n",
    "#             feats = None\n",
    "\n",
    "#         # normalize\n",
    "#         c = pts.mean(0, keepdims=True)\n",
    "#         pts_c = pts - c\n",
    "#         s = np.max(np.linalg.norm(pts_c, axis=1))\n",
    "#         pts_n = pts_c / (s + 1e-8)\n",
    "\n",
    "#         # sample/pad\n",
    "#         N = self.n_points\n",
    "#         if pts_n.shape[0] >= N:\n",
    "#             sel = np.random.choice(pts_n.shape[0], N, replace=False)\n",
    "#         else:\n",
    "#             pad = np.random.choice(pts_n.shape[0], N - pts_n.shape[0], replace=True)\n",
    "#             sel = np.concatenate([np.arange(pts_n.shape[0]), pad])\n",
    "\n",
    "#         self.sel = sel\n",
    "#         self.pts_n = pts_n[sel]                    # (N,3)\n",
    "#         self.feats = feats[sel] if feats is not None else None\n",
    "\n",
    "#     def __len__(self): return 1\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         if self.feats is None:\n",
    "#             x = self.pts_n.T                        # (3,N)\n",
    "#         else:\n",
    "#             x = np.concatenate([self.pts_n, self.feats], axis=1).T  # (3+C, N)\n",
    "#         return torch.from_numpy(x).float()\n",
    "\n",
    "# # Usage\n",
    "# ds = SinglePLYDataset(\"../point_cloud_data/shoe/shoe-poisson-sampled.ply\", n_points=2500, with_normals=False)\n",
    "# dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# for batch in dl:                      # batch: (B, C, N)\n",
    "#     batch = batch.to(device)\n",
    "#     print(batch.shape)\n",
    "#     with torch.no_grad():\n",
    "#         out = classifier(batch)            # or model(batch, onehot) for part-seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "065b2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_preds, x, y = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46dd7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model_preds.shape)\n",
    "# print(x.shape)\n",
    "# print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aebd59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from visual_utils import plot_pc_data3d, plot_bboxes_3d\n",
    "\n",
    "# # Random test sample\n",
    "# # test_sample = test_set[2047]\n",
    "# # batch_dict = collate_fn([test_sample])\n",
    "\n",
    "# # Get model predictions\n",
    "# # x = batch_dict['points'].transpose(1, 2).to(device)\n",
    "# # model_preds, _, _ = classifier(x)\n",
    "# pred_part_labels = torch.argmax(model_preds, axis=1).detach().cpu().numpy()[0]\n",
    "\n",
    "# # points = test_sample['points']\n",
    "# points = ds[0]\n",
    "# # part_labels = test_sample['seg_labels']\n",
    "\n",
    "# PCD_SCENE=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False), aspectmode='data')\n",
    "# NUM_PARTS = 16\n",
    "# PART_COLORS = np.random.choice(range(255),size=(NUM_PARTS,3))\n",
    "\n",
    "# # plot results\n",
    "# fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"scatter3d\"}, {\"type\": \"scatter3d\"}]], column_widths=[0.5, 0.5],\n",
    "#                     subplot_titles=('Part Labels', 'Part Predictions'))\n",
    "\n",
    "# # ground truth part labels\n",
    "# part_label_plots = plot_pc_data3d(x=points[:,0], y=points[:,1], z=points[:,2], apply_color_gradient=False, \n",
    "#                                   color=PART_COLORS[pred_part_labels - 1], marker_size=2)\n",
    "\n",
    "# # ground truth part labels\n",
    "# pred_part_label_plots = plot_pc_data3d(x=points[:,0], y=points[:,1], z=points[:,2], apply_color_gradient=False, \n",
    "#                                   color=PART_COLORS[pred_part_labels - 1], marker_size=2)\n",
    "\n",
    "# fig.update_layout(template=\"plotly_dark\", scene=PCD_SCENE, scene2=PCD_SCENE, height = 720, width = 1280,\n",
    "#                 title='PointNet Semantic Segmentation', title_x=0.5, title_y=0.97, margin=dict(r=0, b=0, l=0, t=0))\n",
    "# fig.add_trace(part_label_plots, row=1, col=1)\n",
    "# fig.add_trace(pred_part_label_plots, row=1, col=2)\n",
    "# #fig.add_trace(plot_pc_data3d(x=test_sample['points'][:,0], y=test_sample['points'][:,1], z=test_sample['points'][:,2]), row=1, col=1)\n",
    "# #fig.add_trace(go.Bar(x=list(class_name_id_map.keys()), y=pred_class_probs, showlegend=False), row=1, col=2)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ce695ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class SinglePLYDataset(Dataset):\n",
    "    def __init__(self, ply_path, n_points=2048, with_normals=False, seed=0):\n",
    "        self.ply_path = ply_path\n",
    "        self.n_points = n_points\n",
    "        self.with_normals = with_normals\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        self._prepare()\n",
    "\n",
    "    def _prepare(self):\n",
    "        pcd = o3d.io.read_point_cloud(self.ply_path)\n",
    "        pts = np.asarray(pcd.points, dtype=np.float32)              # (M,3)\n",
    "        assert pts.shape[0] > 0, \"No points in PLY.\"\n",
    "\n",
    "        if self.with_normals:\n",
    "            if not pcd.has_normals():\n",
    "                pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
    "            feats = np.asarray(pcd.normals, dtype=np.float32)       # (M,3)\n",
    "        else:\n",
    "            feats = None\n",
    "\n",
    "        # normalize to unit sphere\n",
    "        center = pts.mean(0, keepdims=True)\n",
    "        pts_c = pts - center\n",
    "        scale = np.max(np.linalg.norm(pts_c, axis=1))\n",
    "        pts_n = pts_c / (scale + 1e-8)\n",
    "\n",
    "        # sample or pad to N\n",
    "        N = self.n_points\n",
    "        M = pts_n.shape[0]\n",
    "        if M >= N:\n",
    "            sel = self.rng.choice(M, N, replace=False)\n",
    "        else:\n",
    "            pad = self.rng.choice(M, N - M, replace=True)\n",
    "            sel = np.concatenate([np.arange(M), pad])\n",
    "\n",
    "        self.sel = sel\n",
    "        self.center = center\n",
    "        self.scale = scale\n",
    "        self.pts_norm = pts_n[sel]                                   # (N,3) normalized\n",
    "        self.pts_denorm = self.pts_norm * scale + center             # (N,3) original coords (selected)\n",
    "        self.feats = feats[sel] if feats is not None else None\n",
    "\n",
    "    def __len__(self): return 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # (C, N) as most PointNet variants expect (B, C, N)\n",
    "        if self.feats is None:\n",
    "            x = self.pts_norm.T                                      # (3,N)\n",
    "        else:\n",
    "            x = np.concatenate([self.pts_norm, self.feats], axis=1).T  # (3+C, N)\n",
    "        return torch.from_numpy(x).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58b74b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-point labels: shape=(100000,), unique=[0 2 3]; P=16\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Dataset / Loader\n",
    "ds = SinglePLYDataset(\"../point_cloud_data/shoe/shoe-poisson-sampled.ply\", n_points=num_points, with_normals=False, seed=0)\n",
    "dl = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "\n",
    "# 2) Your model (replace this with your actual loaded model)\n",
    "# Example: model = get_pn2_partseg_model(num_classes=50, normal_channel=False)\n",
    "model = classifier.to(device).eval()\n",
    "\n",
    "# 3) Optional: ShapeNetPart coarse-class one-hot\n",
    "coarse = [\"Airplane\",\"Bag\",\"Cap\",\"Car\",\"Chair\",\"Earphone\",\"Guitar\",\"Knife\",\n",
    "          \"Lamp\",\"Laptop\",\"Motorbike\",\"Mug\",\"Pistol\",\"Rocket\",\"Skateboard\",\"Table\"]\n",
    "onehot = torch.zeros(1, len(coarse), device=device)\n",
    "# Pick one *if your forward requires it*. If not needed, you can skip onehot entirely.\n",
    "onehot[0, coarse.index(\"Chair\")] = 1.0  # arbitrary pick to satisfy the interface\n",
    "\n",
    "# 4) Inference (robust to common output shapes / returns)\n",
    "batch = next(iter(dl)).to(device)             # (1, C, N)\n",
    "with torch.no_grad():\n",
    "    try:\n",
    "        out = model(batch, onehot)\n",
    "    except TypeError:\n",
    "        out = model(batch)\n",
    "\n",
    "# Unpack if model returns a tuple\n",
    "logits = out[0] if isinstance(out, (tuple, list)) else out  # (B,*,*) tensor\n",
    "\n",
    "# Make logits shape = (B, N, P)\n",
    "if logits.dim() != 3:\n",
    "    raise RuntimeError(f\"Unexpected logits dim={logits.dim()}, expected 3.\")\n",
    "B, A, C = logits.shape\n",
    "N = ds.pts_norm.shape[0]\n",
    "\n",
    "if A == N:\n",
    "    per_point = logits                                      # (B, N, P)\n",
    "elif C == N:\n",
    "    per_point = logits.transpose(1, 2)                      # (B, N, P) from (B, P, N)\n",
    "else:\n",
    "    # Some heads emit (B, N, P) already but with N not equal to requested â€” warn here\n",
    "    raise RuntimeError(f\"Cannot infer (N,P) axes from shape {tuple(logits.shape)} vs N={N}\")\n",
    "\n",
    "# Argmax to get labels (0..P-1)\n",
    "pred = per_point.argmax(dim=2).squeeze(0).cpu().numpy()     # (N,)\n",
    "num_parts = per_point.shape[-1]\n",
    "print(f\"Per-point labels: shape={pred.shape}, unique={np.unique(pred)}; P={num_parts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77eb1a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../point_cloud_data/shoe/shoe-segmented.ply\n"
     ]
    }
   ],
   "source": [
    "# Color palette\n",
    "rng = np.random.RandomState(0)\n",
    "palette = rng.rand(num_parts, 3)\n",
    "colors = palette[pred]                                      # (N,3)\n",
    "\n",
    "# Save a colored PLY (original coordinates, not normalized)\n",
    "pcd_out = o3d.geometry.PointCloud()\n",
    "pcd_out.points = o3d.utility.Vector3dVector(ds.pts_denorm)  # (N,3)\n",
    "pcd_out.colors = o3d.utility.Vector3dVector(colors)\n",
    "out_path = \"../point_cloud_data/shoe/shoe-segmented.ply\"\n",
    "o3d.io.write_point_cloud(out_path, pcd_out)\n",
    "print(\"Saved:\", out_path)\n",
    "\n",
    "# Static preview (works in headless notebooks)\n",
    "# fig = plt.figure(figsize=(6,6))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(ds.pts_norm[:,0], ds.pts_norm[:,1], ds.pts_norm[:,2], s=2, c=colors)\n",
    "# ax.set_title(\"Predicted parts (normalized coords)\")\n",
    "# ax.set_axis_off()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lumafieldtap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
